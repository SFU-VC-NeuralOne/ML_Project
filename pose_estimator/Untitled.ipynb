{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5001 [00:00<?, ?it/s]\u001b[A\u001b[A/opt/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:140: UserWarning: ../data/target/tmp/label_{item:04d}.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "\n",
      "\n",
      "  0%|          | 1/5001 [00:18<25:37:26, 18.45s/it]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 2/5001 [00:35<24:56:25, 17.96s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-99f04b220e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mcord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcordinates_from_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mpose_cords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdraw_pose_from_cords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-99f04b220e4b>\u001b[0m in \u001b[0;36mcordinates_from_image_file\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageToTest_padded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mpaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriImg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mheatmap_avg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    167\u001b[0m         out = warp(image, tform, output_shape=output_shape, order=order,\n\u001b[1;32m    168\u001b[0m                    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                    preserve_range=preserve_range)\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# n-dimensional interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mwarp\u001b[0;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    849\u001b[0m                                            \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m                                            order=order, mode=mode, cval=cval))\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \"\"\"\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_replace_zero_by_x_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_arys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pose_utils\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import skimage.transform as st\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from numpy.random import shuffle\n",
    "from skimage.transform import resize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage.io import imsave, imread\n",
    "from pose_utils import draw_pose_from_cords\n",
    "\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], [19,20], [21,22],\n",
    "          [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52],\n",
    "          [55,56], [37,38], [45,46]]\n",
    "\n",
    "limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10],\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17],\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "\n",
    "threshold = 0.1\n",
    "boxsize = 368\n",
    "scale_search = [0.5, 1, 1.5, 2]\n",
    "\n",
    "\n",
    "def compute_cordinates(heatmap_avg, paf_avg, oriImg, th1=0.1, th2=0.05):\n",
    "    all_peaks = []\n",
    "    peak_counter = 0\n",
    "\n",
    "    for part in range(18):\n",
    "        map_ori = heatmap_avg[:,:,part]\n",
    "        map = gaussian_filter(map_ori, sigma=3)\n",
    "\n",
    "        map_left = np.zeros(map.shape)\n",
    "        map_left[1:,:] = map[:-1,:]\n",
    "        map_right = np.zeros(map.shape)\n",
    "        map_right[:-1,:] = map[1:,:]\n",
    "        map_up = np.zeros(map.shape)\n",
    "        map_up[:,1:] = map[:,:-1]\n",
    "        map_down = np.zeros(map.shape)\n",
    "        map_down[:,:-1] = map[:,1:]\n",
    "\n",
    "        peaks_binary = np.logical_and.reduce((map>=map_left, map>=map_right, map>=map_up, map>=map_down, map > th1))\n",
    "        peaks = list(zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0])) # note reverse\n",
    "\n",
    "        peaks_with_score = [x + (map_ori[x[1],x[0]],) for x in peaks]\n",
    "        id = list(range(peak_counter, peak_counter + len(peaks)))\n",
    "        peaks_with_score_and_id = [peaks_with_score[i] + (id[i],) for i in range(len(id))]\n",
    "\n",
    "        all_peaks.append(peaks_with_score_and_id)\n",
    "        peak_counter += len(peaks)\n",
    "\n",
    "    connection_all = []\n",
    "    special_k = []\n",
    "    mid_num = 10\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        score_mid = paf_avg[:,:,[x-19 for x in mapIdx[k]]]\n",
    "        candA = all_peaks[limbSeq[k][0]-1]\n",
    "        candB = all_peaks[limbSeq[k][1]-1]\n",
    "        nA = len(candA)\n",
    "        nB = len(candB)\n",
    "        indexA, indexB = limbSeq[k]\n",
    "        if(nA != 0 and nB != 0):\n",
    "            connection_candidate = []\n",
    "            for i in range(nA):\n",
    "                for j in range(nB):\n",
    "                    vec = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                    norm = np.sqrt(vec[0]*vec[0] + vec[1]*vec[1])\n",
    "                    vec = np.divide(vec, norm)\n",
    "\n",
    "                    startend = list(zip(np.linspace(candA[i][0], candB[j][0], num=mid_num),\n",
    "                                   np.linspace(candA[i][1], candB[j][1], num=mid_num)))\n",
    "\n",
    "                    vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0]\n",
    "                                      for I in range(len(startend))])\n",
    "                    vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1]\n",
    "                                      for I in range(len(startend))])\n",
    "\n",
    "                    score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                    score_with_dist_prior = sum(score_midpts)/len(score_midpts) + min(0.5*oriImg.shape[0]/norm-1, 0)\n",
    "                    criterion1 = len(np.nonzero(score_midpts > th2)[0]) > 0.8 * len(score_midpts)\n",
    "                    criterion2 = score_with_dist_prior > 0\n",
    "                    if criterion1 and criterion2:\n",
    "                        connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior+candA[i][2]+candB[j][2]])\n",
    "\n",
    "            connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
    "            connection = np.zeros((0,5))\n",
    "            for c in range(len(connection_candidate)):\n",
    "                i,j,s = connection_candidate[c][0:3]\n",
    "                if(i not in connection[:,3] and j not in connection[:,4]):\n",
    "                    connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n",
    "                    if(len(connection) >= min(nA, nB)):\n",
    "                        break\n",
    "\n",
    "            connection_all.append(connection)\n",
    "        else:\n",
    "            special_k.append(k)\n",
    "            connection_all.append([])\n",
    "\n",
    "    # last number in each row is the total parts number of that person\n",
    "    # the second last number in each row is the score of the overall configuration\n",
    "    subset = -1 * np.ones((0, 20))\n",
    "    candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
    "\n",
    "    for k in range(len(mapIdx)):\n",
    "        if k not in special_k:\n",
    "            partAs = connection_all[k][:,0]\n",
    "            partBs = connection_all[k][:,1]\n",
    "            indexA, indexB = np.array(limbSeq[k]) - 1\n",
    "\n",
    "            for i in range(len(connection_all[k])): #= 1:size(temp,1)\n",
    "                found = 0\n",
    "                subset_idx = [-1, -1]\n",
    "                for j in range(len(subset)): #1:size(subset,1):\n",
    "                    if subset[j][indexA] == partAs[i] or subset[j][indexB] == partBs[i]:\n",
    "                        subset_idx[found] = j\n",
    "                        found += 1\n",
    "\n",
    "                if found == 1:\n",
    "                    j = subset_idx[0]\n",
    "                    if(subset[j][indexB] != partBs[i]):\n",
    "                        subset[j][indexB] = partBs[i]\n",
    "                        subset[j][-1] += 1\n",
    "                        subset[j][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "                elif found == 2: # if found 2 and disjoint, merge them\n",
    "                    j1, j2 = subset_idx\n",
    "                    print(\"found = 2\")\n",
    "                    membership = ((subset[j1]>=0).astype(int) + (subset[j2]>=0).astype(int))[:-2]\n",
    "                    if len(np.nonzero(membership == 2)[0]) == 0: #merge\n",
    "                        subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
    "                        subset[j1][-2:] += subset[j2][-2:]\n",
    "                        subset[j1][-2] += connection_all[k][i][2]\n",
    "                        subset = np.delete(subset, j2, 0)\n",
    "                    else: # as like found == 1\n",
    "                        subset[j1][indexB] = partBs[i]\n",
    "                        subset[j1][-1] += 1\n",
    "                        subset[j1][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "\n",
    "                # if find no partA in the subset, create a new subset\n",
    "                elif not found and k < 17:\n",
    "                    row = -1 * np.ones(20)\n",
    "                    row[indexA] = partAs[i]\n",
    "                    row[indexB] = partBs[i]\n",
    "                    row[-1] = 2\n",
    "                    row[-2] = sum(candidate[connection_all[k][i,:2].astype(int), 2]) + connection_all[k][i][2]\n",
    "                    subset = np.vstack([subset, row])\n",
    "\n",
    "    # delete some rows of subset which has few parts occur\n",
    "    deleteIdx = [];\n",
    "    for i in range(len(subset)):\n",
    "        if subset[i][-1] < 4 or subset[i][-2]/subset[i][-1] < 0.4:\n",
    "            deleteIdx.append(i)\n",
    "    subset = np.delete(subset, deleteIdx, axis=0)\n",
    "\n",
    "    if len(subset) == 0:\n",
    "        return np.array([[-1, -1]] * 18).astype(int)\n",
    "\n",
    "    cordinates = []\n",
    "    result_image_index = np.argmax(subset[:, -2])\n",
    "\n",
    "    for part in subset[result_image_index, :18]:\n",
    "        if part == -1:\n",
    "            cordinates.append([-1, -1])\n",
    "        else:\n",
    "            Y = candidate[part.astype(int), 0]\n",
    "            X = candidate[part.astype(int), 1]\n",
    "            cordinates.append([X, Y])\n",
    "    return np.array(cordinates).astype(int)\n",
    "\n",
    "\n",
    "#def cordinates_from_image_file(image_name, model):\n",
    "#   oriImg = imread(image_name)[:, :, ::-1]  # B,G,R order\n",
    "def cordinates_from_image_file(image, model):\n",
    "    oriImg = image[:, :, ::-1]\n",
    "\n",
    "    multiplier = [x * boxsize / oriImg.shape[0] for x in scale_search]\n",
    "\n",
    "    heatmap_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 19))\n",
    "    paf_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 38))\n",
    "\n",
    "    for m in range(len(multiplier)):\n",
    "        scale = multiplier[m]\n",
    "\n",
    "        new_size = (np.array(oriImg.shape[:2]) * scale).astype(np.int32)\n",
    "        imageToTest = resize(oriImg, new_size, order=3, preserve_range=True)\n",
    "        imageToTest_padded = imageToTest[np.newaxis, :, :, :]/255 - 0.5\n",
    "\n",
    "        output1, output2 = model.predict(imageToTest_padded)\n",
    "\n",
    "        heatmap = st.resize(output2[0], oriImg.shape[:2], preserve_range=True, order=1)\n",
    "        paf = st.resize(output1[0], oriImg.shape[:2], preserve_range=True, order=1)\n",
    "        heatmap_avg += heatmap\n",
    "        paf_avg += paf\n",
    "\n",
    "    heatmap_avg /= len(multiplier)\n",
    "    pose_cords = compute_cordinates(heatmap_avg, paf_avg, oriImg=oriImg)\n",
    "    return pose_cords\n",
    "\n",
    "def strip_frames(vdir, input, output, num=625):\n",
    "\n",
    "    reader = get_reader(os.path.join(vdir, input))\n",
    "    fps = reader.get_meta_data()['fps']\n",
    "    writer = get_writer(os.path.join(vdir, output), fps=fps)\n",
    "\n",
    "    count = 0\n",
    "    for im in reader:\n",
    "        count += 1\n",
    "        if count > num:\n",
    "            writer.append_data(im)\n",
    "\n",
    "    print(count)\n",
    "    writer.close()\n",
    "\n",
    "\n",
    "# check if a given image contains full skeleton info\n",
    "# criterion: 18 color points. (color points means RGB variance larger than threshold)\n",
    "def check_validity(img, thres=70, keypoint_num=18):\n",
    "    def get_cords(im, thrs):\n",
    "        color_points = np.argwhere(np.max(im, axis=2) - np.min(im, axis=2) > thrs)\n",
    "        dict_cords = {(i[0], i[1]): 0 for i in color_points}\n",
    "        mask = np.zeros(img.shape[0:2], dtype=np.uint8)\n",
    "        for k in dict_cords:\n",
    "            mask[k[0], k[1]] = 255\n",
    "        return dict_cords, mask\n",
    "\n",
    "    cords, mask = get_cords(img, thres)\n",
    "    _joint_num = 0\n",
    "    for k, v in cords.items():\n",
    "        if (k[0] - 1, k[1]) in cords:\n",
    "            cords[k] = cords[(k[0] - 1, k[1])]\n",
    "        elif (k[0], k[1] - 1) in cords:\n",
    "            cords[k] = cords[(k[0], k[1] - 1)]\n",
    "        elif (k[0] - 1, k[1] - 1) in cords:\n",
    "            cords[k] = cords[(k[0] - 1, k[1] - 1)]\n",
    "        else:\n",
    "            _joint_num += 1\n",
    "            cords[k] = _joint_num\n",
    "    return _joint_num, mask\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    img_dir = '../data/target/images/'  # Change this line into where your video frames are stored\n",
    "    pose_dir = '../data/target/tmp/'\n",
    "    pose_npy_name = '../data/target/tmp'\n",
    "    if not os.path.isdir(pose_dir):\n",
    "        os.mkdir(pose_dir)\n",
    "\n",
    "    model = load_model('./pose_estimator.h5')\n",
    "    model.cuda()\n",
    "    img_list = os.listdir(img_dir)\n",
    "    # get frame shape\n",
    "    tmp = imread(os.path.join(img_dir, img_list[0]))\n",
    "    im_shape = tmp.shape[:-1] \n",
    "    pose_cords = []\n",
    "    for item in tqdm(img_list):\n",
    "        img = imread(os.path.join(img_dir, item))\n",
    "        cord = cordinates_from_image_file(img, model=model)\n",
    "        pose_cords.append(cord)\n",
    "        color,_ = draw_pose_from_cords(cord, im_shape)\n",
    "        imsave(os.path.join(pose_dir,('label_{item:04d}.png')), color)\n",
    "    np.save(pose_npy_name, np.array(pose_cords, dtype=np.int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-82a2544f35a3>, line 260)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-82a2544f35a3>\"\u001b[0;36m, line \u001b[0;32m260\u001b[0m\n\u001b[0;31m    print(img)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
