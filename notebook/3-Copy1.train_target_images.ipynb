{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2b5cdbc4c56c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#from options.train_options import TrainOptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCreateDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "#from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "opt.debug=False\n",
    "opt.no_html=False\n",
    "opt.continue_train=False\n",
    "opt.dataroot='/home/mannatk/mlProject/pytorch-EverybodyDanceNow-master/data/target/5000afro'\n",
    "opt.num_D=2\n",
    "opt.batchSize=1\n",
    "opt.niter=10\n",
    "opt.niter_decay=10\n",
    "opt.max_dataset_size=500\n",
    "\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0\n",
    "\n",
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10\n",
    "\n",
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('#training images = %d' % dataset_size)\n",
    "\n",
    "model = create_model(opt)\n",
    "visualizer = Visualizer(opt)\n",
    "\n",
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq\n",
    "\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        save_fake = total_steps % opt.display_freq == display_delta\n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        losses, generated = model(Variable(data['label']), Variable(data['inst']), \n",
    "            Variable(data['image']), Variable(data['feat']), infer=save_fake)\n",
    "\n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN'] + loss_dict.get('G_GAN_Feat',0) + loss_dict.get('G_VGG',0)\n",
    "\n",
    "        ############### Backward Pass ####################\n",
    "        # update generator weights\n",
    "        model.module.optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        model.module.optimizer_G.step()\n",
    "\n",
    "        # update discriminator weights\n",
    "        model.module.optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        model.module.optimizer_D.step()\n",
    "\n",
    "        #call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]) \n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "        ### print out errors\n",
    "        if total_steps % opt.print_freq == print_delta:\n",
    "            errors = {k: v.data[0] if not isinstance(v, int) else v for k, v in loss_dict.items()}\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "            visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
    "            visualizer.plot_current_errors(errors, total_steps)\n",
    "\n",
    "        ### display output images\n",
    "        if save_fake:\n",
    "            visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\n",
    "                                   ('synthesized_image', util.tensor2im(generated.data[0])),\n",
    "                                   ('real_image', util.tensor2im(data['image'][0]))])\n",
    "            visualizer.display_current_results(visuals, epoch, total_steps)\n",
    "\n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            model.module.save('latest')            \n",
    "            np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix2pixhd_dir = Path('../src/pix2pixHD/')\n",
    "\n",
    "import sys\n",
    "sys.path.append(str(pix2pixhd_dir))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "from util.visualizer import Visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yijun's implementation:\n",
    "    Get the faces\n",
    "    Get the facial landmarks\n",
    "    Save it in target/faces as train_img,train_label\n",
    "    \n",
    "\n",
    "def get_faces_labels(Body_img):\n",
    "    face_img=crop(Body_img)\n",
    "    face_label=detect_facial(face_img)\n",
    "    face_img.save('../data/target/faces/train_img')\n",
    "    return face_img,face_label,positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batchSize=1, beta1=0.5, checkpoints_dir='../checkpoints/', continue_train=False, data_type=32, dataroot='../data/target/faces', debug=True, display_freq=640, display_winsize=512, feat_num=3, fineSize=512, fine_size=480, gpu_ids=[0], input_nc=3, instance_feat=False, isTrain=True, label_feat=False, label_nc=18, lambda_feat=10.0, loadSize=512, load_features=False, load_pretrain='', lr=0.0002, max_dataset_size=inf, model='pix2pixHD', nThreads=2, n_blocks_global=9, n_blocks_local=3, n_clusters=10, n_downsample_E=4, n_downsample_global=4, n_layers_D=3, n_local_enhancers=1, name='target', ndf=64, nef=16, netG='global', ngf=64, niter=20, niter_decay=20, niter_fix_global=0, no_flip=False, no_ganFeat_loss=False, no_html=False, no_instance=True, no_lsgan=False, no_vgg_loss=False, norm='instance', num_D=3, output_nc=3, phase='train', pool_size=0, print_freq=640, resize_or_crop='scale_width', save_epoch_freq=10, save_latest_freq=640, serial_batches=False, tf_log=False, use_dropout=False, verbose=False, which_epoch=0)\n"
     ]
    }
   ],
   "source": [
    "with open('../data/train_opt.pkl', mode='rb') as f:\n",
    "    opt = pickle.load(f)\n",
    "    \n",
    "opt.debug=True\n",
    "opt.no_html=False\n",
    "opt.dataroot=\"../data/target/faces\"\n",
    "opt.continue_train=False\n",
    "opt.which_epoch=0\n",
    "opt.num_D=3\n",
    "print(opt)\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomDatasetDataLoader\n",
      "dataset [AlignedDataset] was created\n",
      "#training images = 200\n"
     ]
    }
   ],
   "source": [
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('#training images = %d' % dataset_size)\n",
    "    \n",
    "start_epoch, epoch_iter = 0, 0\n",
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq\n",
    "end_epoch=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GlobalGenerator(\n",
      "  (model): Sequential(\n",
      "    (0): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (1): Conv2d(18, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (11): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (12): ReLU(inplace)\n",
      "    (13): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (14): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (15): ReLU(inplace)\n",
      "    (16): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (17): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (18): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (19): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (20): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (21): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (22): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (23): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (24): ResnetBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (2): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "        (3): ReLU(inplace)\n",
      "        (4): ReflectionPad2d((1, 1, 1, 1))\n",
      "        (5): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
      "        (6): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      )\n",
      "    )\n",
      "    (25): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (26): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (27): ReLU(inplace)\n",
      "    (28): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (29): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (30): ReLU(inplace)\n",
      "    (31): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (32): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (33): ReLU(inplace)\n",
      "    (34): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
      "    (35): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (36): ReLU(inplace)\n",
      "    (37): ReflectionPad2d((3, 3, 3, 3))\n",
      "    (38): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (39): Tanh()\n",
      "  )\n",
      ")\n",
      "MultiscaleDiscriminator(\n",
      "  (scale0_layer0): Sequential(\n",
      "    (0): Conv2d(21, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale0_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale1_layer0): Sequential(\n",
      "    (0): Conv2d(21, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale1_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (scale2_layer0): Sequential(\n",
      "    (0): Conv2d(21, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale2_layer1): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale2_layer2): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale2_layer3): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace)\n",
      "  )\n",
      "  (scale2_layer4): Sequential(\n",
      "    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
      "  )\n",
      "  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create web directory ../checkpoints/target/web...\n"
     ]
    }
   ],
   "source": [
    "def put_head_bk(head_image, body_image, head_position):\n",
    "    head_image = Image.open('/home/yza476/Desktop/Figure_6_lr0_000001.png', 'r')\n",
    "    img_w, img_h = head_image.size\n",
    "    body_image = Image.new('RGBA', (1440, 900), (255, 0, 255, 255))\n",
    "    #bg_w, bg_h = body_image.size\n",
    "    offset = (head_position[1],head_position[1])\n",
    "    body_image.paste(body_image, offset)\n",
    "    return body_image\n",
    "\n",
    "face_model = create_model(opt)\n",
    "body_model = create_model(opt)\n",
    "visualizer = Visualizer(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of epoch 0 / 20 \t Time Taken: 127 sec\n",
      "saving the model at the end of epoch 0, iters 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, end_epoch):#opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        save_fake = total_steps % opt.display_freq == display_delta\n",
    "        \n",
    "        ############## Forward Pass ######################\n",
    "        losses, generated = face_model(Variable(data['label']), Variable(data['inst']), \n",
    "            Variable(data['image']), Variable(data['feat']), infer=save_fake)\n",
    "\n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(face_model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN'] + loss_dict.get('G_GAN_Feat',0) + loss_dict.get('G_VGG',0)\n",
    "\n",
    "        ############### Backward Pass ####################\n",
    "        # update generator weights\n",
    "        face_model.module.optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        face_model.module.optimizer_G.step()\n",
    "\n",
    "        # update discriminator weights\n",
    "        face_model.module.optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        face_model.module.optimizer_D.step()\n",
    "\n",
    "       # call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]) \n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "        ### print out errors\n",
    "        if total_steps % opt.print_freq == print_delta:\n",
    "            errors = {k: v.data[0] if not isinstance(v, int) else v for k, v in loss_dict.items()}\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "            visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
    "            visualizer.plot_current_errors(errors, total_steps)\n",
    "\n",
    "        ### display output images\n",
    "        if save_fake:\n",
    "            visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\n",
    "                                   ('synthesized_image', util.tensor2im(generated.data[0])),\n",
    "                                   ('real_image', util.tensor2im(data['image'][0]))])\n",
    "            visualizer.display_current_results(visuals, epoch, total_steps)\n",
    "\n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            face_model.module.save('latest')            \n",
    "            np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "\n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, end_epoch, time.time() - epoch_start_time))\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        face_model.module.save('latest')\n",
    "        face_model.module.save(epoch)\n",
    "        np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        face_model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        face_model.module.update_learning_rate()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, end_epoch):#opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        save_fake = total_steps % opt.display_freq == display_delta\n",
    "        \n",
    "        face,face_label,positions=get_face_label(data['image'])\n",
    "        generated_face = face_model.inference(face_label, data['inst'])\n",
    "        ############## Forward Pass ######################\n",
    "        losses, generated = body_model(Variable(data['label']), Variable(data['inst']), \n",
    "            Variable(data['image']), Variable(data['feat']), infer=save_fake,'body',generated_face,positions)\n",
    "\n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(body_model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN'] + loss_dict.get('G_GAN_Feat',0) + loss_dict.get('G_VGG',0)\n",
    "\n",
    "        ############### Backward Pass ####################\n",
    "        # update generator weights\n",
    "        body_model.module.optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        body_model.module.optimizer_G.step()\n",
    "\n",
    "        # update discriminator weights\n",
    "        body_model.module.optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        body_model.module.optimizer_D.step()\n",
    "\n",
    "       # call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]) \n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "        ### print out errors\n",
    "        if total_steps % opt.print_freq == print_delta:\n",
    "            errors = {k: v.data[0] if not isinstance(v, int) else v for k, v in loss_dict.items()}\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "            visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
    "            visualizer.plot_current_errors(errors, total_steps)\n",
    "\n",
    "        ### display output images\n",
    "        if save_fake:\n",
    "            visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\n",
    "                                   ('synthesized_image', util.tensor2im(generated.data[0])),\n",
    "                                   ('real_image', util.tensor2im(data['image'][0]))])\n",
    "            visualizer.display_current_results(visuals, epoch, total_steps)\n",
    "\n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            body_model.module.save('latest')            \n",
    "            np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "\n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, end_epoch, time.time() - epoch_start_time))\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        body_model.module.save('latest')\n",
    "        body_model.module.save(epoch)\n",
    "        np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        body_model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        body_model.module.update_learning_rate()\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
